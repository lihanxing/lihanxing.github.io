---
layout: post
title:  "CUDA编程"
date:   2022-08-23
categories: CUDA
---
* content
{:toc}

*本文部分来源和文字来源于网络，本文主要目的是个人学习*

---
#### 前言
> CUDA是简历在NVIDIA的GPU上(`Graphics Processing Unit`)的通用并行计算平台和编程模型，基于CUDA的编程可以利用GPU的并行计算引擎高效地解决较复杂的计算问题。

> 不过GPU不是一个独立运行的计算平台，需要与CPU协同工作，可以看成是CPU的协处理器。当我们说GPU并行计算时，其实指的是基于CPU+GPU的异构计算架构。在异构计算架构中，GPU与CPU通过PCle总线链接在一起协同工作，CPU所在位置被称为主机端(`host`)，而GPU所在设备称为设备端(`device`)。

---
#### CUDA编程模型基础
> 上面讲到CUDA编程模型是一个异构模型，需要CPU与GPU协同工作(~~我理解的是CPU指挥，GPU执行~~)。在CUDA编程中，**host**和**device**是两个概念，**host**指CPU及其内存，**device**指GPU及其内存。
> CUDA程序中既有host程序也有device程序，分别在CPU和GPU上运行。同时host和device之间可以进行通信，实现数据的拷贝。

> 典型的CUDA程序的执行流程如下：
> * 分配host内存，并进行数据初始化；
> * 分配device内存，并从host上将数据拷贝到device上；
> * 调用CUDA的核函数在device上完成指定的运算；
> * 将device上的运算结果拷贝到host上；
> * 释放device和host上分配的内存。

> 其中最重要的过程是调用CUDA的核函数来实施并行计算，Kernel是CUDA中一个非常重要的概念，kernel是在device线程中并行执行的函数，核函数用`--global--`符号声明，在调用时需要用`<<<grid,block>>>`指定kernel需要执行的线程数量，在CUDA中每一个线程都要执行核函数，并且每个线程会分配一个唯一的线程号thread ID，这个ID值可以通过核函数的内置变量`threadIdx`获得

>上面我们讲到了GPU实际上是异构模型，所以需要区分是在host或device上运行的代码，在CUDA中是通过函数类型限定词区别host和device上的函数，主要的三种类型限定词如下：
>* `--global--`:在device上执行，从host中调用(一些特定的GPU也可以从device上调用)，返回类型必须是void，不支持可变参数参数，不能成为类成员函数。注意使用`--global--`定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。
>* `__device__`:在device上执行，单仅可以从device中调用，不可以和`__global__`同时用。
>* `__host__`：在host上执行，仅可以从host上调用，一般省略不写，不可以和`__global__`同时用，但可和`__device__`，此时函数会在device和host都编译。
